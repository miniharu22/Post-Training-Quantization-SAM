{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOmkPoo+WKNhx+HD6DkL7w9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MjdSabZqT89","executionInfo":{"status":"ok","timestamp":1750160059339,"user_tz":-540,"elapsed":46183,"user":{"displayName":"이상민","userId":"08174984398159451432"}},"outputId":"7c521183-88d5-4685-b1a4-7f48480cd026"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.6.0+cu124\n","Torchvision version: 0.21.0+cu124\n","CUDA is available: True\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Collecting onnx\n","  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.0\n","Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-g6udlqr3\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-g6udlqr3\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: segment_anything\n","  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=471c9a4d03bbaeebe7bb4568dafb7c929932609d375d4c3068df814eea2eab8a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-g4nupjos/wheels/15/d7/bd/05f5f23b7dcbe70cbc6783b06f12143b0cf1a5da5c7b52dcc5\n","Successfully built segment_anything\n","Installing collected packages: segment_anything\n","Successfully installed segment_anything-1.0\n","--2025-06-17 11:33:56--  https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 271475 (265K) [image/jpeg]\n","Saving to: ‘images/truck.jpg’\n","\n","truck.jpg           100%[===================>] 265.11K  --.-KB/s    in 0.02s   \n","\n","2025-06-17 11:33:57 (11.1 MB/s) - ‘images/truck.jpg’ saved [271475/271475]\n","\n","--2025-06-17 11:33:57--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.15, 13.226.210.78, 13.226.210.25, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2564550879 (2.4G) [binary/octet-stream]\n","Saving to: ‘sam_vit_h_4b8939.pth’\n","\n","sam_vit_h_4b8939.pt 100%[===================>]   2.39G  31.3MB/s    in 22s     \n","\n","2025-06-17 11:34:19 (113 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n","\n"]}],"source":["using_colab = True\n","\n","if using_colab:\n","    import torch\n","    import torchvision\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib onnx onnxruntime\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n","\n","    !mkdir images\n","    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n","\n","    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from segment_anything import sam_model_registry, SamPredictor\n","from segment_anything.utils.onnx import SamOnnxModel\n","\n","import onnxruntime\n","from onnxruntime.quantization import QuantType\n","from onnxruntime.quantization.quantize import quantize_dynamic"],"metadata":{"id":"Qyf2iAwerCcw","executionInfo":{"status":"ok","timestamp":1750160133747,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","userId":"08174984398159451432"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"sam_vit_h_4b8939.pth\"\n","model_type = \"vit_h\""],"metadata":{"id":"zdUDzcXGrE3B","executionInfo":{"status":"ok","timestamp":1750160139624,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","userId":"08174984398159451432"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["sam = sam_model_registry[model_type](checkpoint=checkpoint)"],"metadata":{"id":"7MM0URq3rGSo","executionInfo":{"status":"ok","timestamp":1750160159436,"user_tz":-540,"elapsed":13396,"user":{"displayName":"이상민","userId":"08174984398159451432"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import warnings\n","\n","onnx_model_path = \"sam_onnx_example.onnx\"\n","\n","onnx_model = SamOnnxModel(sam, return_single_mask=True)\n","\n","dynamic_axes = {\n","    \"point_coords\": {1: \"num_points\"},\n","    \"point_labels\": {1: \"num_points\"},\n","}\n","\n","embed_dim = sam.prompt_encoder.embed_dim\n","embed_size = sam.prompt_encoder.image_embedding_size\n","mask_input_size = [4 * x for x in embed_size]\n","dummy_inputs = {\n","    \"image_embeddings\": torch.randn(1, embed_dim, *embed_size, dtype=torch.float),\n","    \"point_coords\": torch.randint(low=0, high=1024, size=(1, 5, 2), dtype=torch.float),\n","    \"point_labels\": torch.randint(low=0, high=4, size=(1, 5), dtype=torch.float),\n","    \"mask_input\": torch.randn(1, 1, *mask_input_size, dtype=torch.float),\n","    \"has_mask_input\": torch.tensor([1], dtype=torch.float),\n","    \"orig_im_size\": torch.tensor([1500, 2250], dtype=torch.float),\n","}\n","output_names = [\"masks\", \"iou_predictions\", \"low_res_masks\"]\n","\n","with warnings.catch_warnings():\n","    warnings.filterwarnings(\"ignore\", category=torch.jit.TracerWarning)\n","    warnings.filterwarnings(\"ignore\", category=UserWarning)\n","    with open(onnx_model_path, \"wb\") as f:\n","        torch.onnx.export(\n","            onnx_model,\n","            tuple(dummy_inputs.values()),\n","            f,\n","            export_params=True,\n","            verbose=False,\n","            opset_version=17,\n","            do_constant_folding=True,\n","            input_names=list(dummy_inputs.keys()),\n","            output_names=output_names,\n","            dynamic_axes=dynamic_axes,\n","        )"],"metadata":{"id":"9txAby2QrH3I","executionInfo":{"status":"ok","timestamp":1750160187220,"user_tz":-540,"elapsed":4042,"user":{"displayName":"이상민","userId":"08174984398159451432"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kPwaIKPdrWy8"},"execution_count":null,"outputs":[]}]}